{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic Dataset Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Estimate Type</th>\n",
       "      <th>Predicted Value</th>\n",
       "      <th>Real Value</th>\n",
       "      <th>Company</th>\n",
       "      <th>Analyst</th>\n",
       "      <th>Bank</th>\n",
       "      <th>Market Cap</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Start Date</th>\n",
       "      <th>Horizon</th>\n",
       "      <th>Revision Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q1 2013</td>\n",
       "      <td>Stock Price</td>\n",
       "      <td>3.083182e+01</td>\n",
       "      <td>75.999668</td>\n",
       "      <td>Company5</td>\n",
       "      <td>Analyst513</td>\n",
       "      <td>Credit Suisse</td>\n",
       "      <td>Mid Cap</td>\n",
       "      <td>Technology</td>\n",
       "      <td>2013-02-19</td>\n",
       "      <td>Q0</td>\n",
       "      <td>Initial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q1 2013</td>\n",
       "      <td>Stock Price</td>\n",
       "      <td>3.657365e+01</td>\n",
       "      <td>75.999668</td>\n",
       "      <td>Company5</td>\n",
       "      <td>Analyst513</td>\n",
       "      <td>Morgan Stanley</td>\n",
       "      <td>Mid Cap</td>\n",
       "      <td>Technology</td>\n",
       "      <td>2013-02-19</td>\n",
       "      <td>Q1</td>\n",
       "      <td>Initial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q1 2013</td>\n",
       "      <td>Stock Price</td>\n",
       "      <td>4.628826e+01</td>\n",
       "      <td>75.999668</td>\n",
       "      <td>Company5</td>\n",
       "      <td>Analyst513</td>\n",
       "      <td>Barclays</td>\n",
       "      <td>Mid Cap</td>\n",
       "      <td>Technology</td>\n",
       "      <td>2013-02-19</td>\n",
       "      <td>Q2</td>\n",
       "      <td>Initial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q1 2013</td>\n",
       "      <td>EBITDA</td>\n",
       "      <td>1.291998e+09</td>\n",
       "      <td>5748714647.472132</td>\n",
       "      <td>Company5</td>\n",
       "      <td>Analyst513</td>\n",
       "      <td>Barclays</td>\n",
       "      <td>Mid Cap</td>\n",
       "      <td>Technology</td>\n",
       "      <td>2013-02-19</td>\n",
       "      <td>Q0</td>\n",
       "      <td>Initial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q1 2013</td>\n",
       "      <td>EBITDA</td>\n",
       "      <td>1.221465e+09</td>\n",
       "      <td>5748714647.472132</td>\n",
       "      <td>Company5</td>\n",
       "      <td>Analyst513</td>\n",
       "      <td>JP Morgan</td>\n",
       "      <td>Mid Cap</td>\n",
       "      <td>Technology</td>\n",
       "      <td>2013-02-19</td>\n",
       "      <td>Q1</td>\n",
       "      <td>Initial</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Quarter Estimate Type  Predicted Value         Real Value   Company  \\\n",
       "0  Q1 2013   Stock Price     3.083182e+01          75.999668  Company5   \n",
       "1  Q1 2013   Stock Price     3.657365e+01          75.999668  Company5   \n",
       "2  Q1 2013   Stock Price     4.628826e+01          75.999668  Company5   \n",
       "3  Q1 2013        EBITDA     1.291998e+09  5748714647.472132  Company5   \n",
       "4  Q1 2013        EBITDA     1.221465e+09  5748714647.472132  Company5   \n",
       "\n",
       "      Analyst            Bank Market Cap      Sector Start Date Horizon  \\\n",
       "0  Analyst513   Credit Suisse    Mid Cap  Technology 2013-02-19      Q0   \n",
       "1  Analyst513  Morgan Stanley    Mid Cap  Technology 2013-02-19      Q1   \n",
       "2  Analyst513        Barclays    Mid Cap  Technology 2013-02-19      Q2   \n",
       "3  Analyst513        Barclays    Mid Cap  Technology 2013-02-19      Q0   \n",
       "4  Analyst513       JP Morgan    Mid Cap  Technology 2013-02-19      Q1   \n",
       "\n",
       "  Revision Time  \n",
       "0       Initial  \n",
       "1       Initial  \n",
       "2       Initial  \n",
       "3       Initial  \n",
       "4       Initial  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.linalg import cholesky\n",
    "\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# -------------------------------\n",
    "# 1. Basic Constants\n",
    "# -------------------------------\n",
    "NUM_COMPANIES = 1000\n",
    "NUM_ANALYSTS = 700\n",
    "YEARS = 10\n",
    "ESTIMATE_TYPES = [\"Stock Price\", \"EBITDA\", \"EPS\", \"Revenue\", \"EBIT\"]\n",
    "SECTORS = [\"Technology\", \"Healthcare\", \"Finance\", \"Energy\", \"Consumer Goods\", \"Industrial\", \"Real Estate\"]\n",
    "MARKET_CAPS = [\"Large Cap\", \"Mid Cap\", \"Small Cap\"]\n",
    "HORIZONS = [\"Q0\", \"Q1\", \"Q2\"]\n",
    "\n",
    "BANKS = [\n",
    "    \"JP Morgan\", \"Goldman Sachs\", \"Morgan Stanley\", \"Citi\", \"Bank of America\",\n",
    "    \"Deutsche Bank\", \"UBS\", \"Credit Suisse\", \"Barclays\", \"Wells Fargo\"\n",
    "]\n",
    "\n",
    "# Ranges for initial values and vol for each estimate\n",
    "ESTIMATE_PARAMS = {\n",
    "    \"Stock Price\": {\"init\": (5, 200), \"vol\": (0.1, 0.3)},\n",
    "    \"EBITDA\": {\"init\": (1e7, 2e9), \"vol\": (0.05, 0.2)},\n",
    "    \"EPS\": {\"init\": (0.1, 20), \"vol\": (0.05, 0.25)},\n",
    "    \"Revenue\": {\"init\": (1e8, 1e10), \"vol\": (0.05, 0.15)},\n",
    "    \"EBIT\": {\"init\": (5e6, 2e9), \"vol\": (0.05, 0.2)}\n",
    "}\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Calendar Setup (Daily with Quarters)\n",
    "# -------------------------------\n",
    "start_date = pd.Timestamp(\"2013-01-01\")\n",
    "end_date = pd.Timestamp(\"2023-01-01\")\n",
    "trading_days = pd.date_range(start=start_date, end=end_date, freq='B')\n",
    "n_days = len(trading_days)\n",
    "\n",
    "# Identify quarter-end days (last trading day each quarter)\n",
    "quarter_ends = trading_days.to_series().groupby(trading_days.to_period(\"Q\")).last().values\n",
    "quarter_ends = pd.to_datetime(quarter_ends)  # ensure Timestamps\n",
    "\n",
    "# We'll store daily indexes for quick lookup\n",
    "day_to_idx = {day: i for i, day in enumerate(trading_days)}\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Market Regimes & Sentiment\n",
    "# -------------------------------\n",
    "REGIME_NAMES = [\"Bull\", \"Bear\"]\n",
    "REGIME_TRANSITION = {\n",
    "    \"Bull\": {\"Bull\": 0.90, \"Bear\": 0.10},\n",
    "    \"Bear\": {\"Bull\": 0.20, \"Bear\": 0.80}\n",
    "}\n",
    "\n",
    "def next_regime(current_regime):\n",
    "    probs = REGIME_TRANSITION[current_regime]\n",
    "    return np.random.choice(list(probs.keys()), p=list(probs.values()))\n",
    "\n",
    "def generate_sentiment_series(n_days):\n",
    "    \"\"\"\n",
    "    Creates a random-walk 'sentiment' factor around 0, with slight mean reversion.\n",
    "    Positive => higher drift, negative => lower drift.\n",
    "    \"\"\"\n",
    "    sentiment = np.zeros(n_days)\n",
    "    for i in range(1, n_days):\n",
    "        sentiment[i] = sentiment[i-1] + np.random.normal(0, 0.01)\n",
    "        # mean-revert slightly\n",
    "        sentiment[i] -= 0.001 * sentiment[i]\n",
    "    return sentiment\n",
    "\n",
    "market_sentiment = generate_sentiment_series(n_days)\n",
    "\n",
    "# We'll store a daily regime array\n",
    "market_regime = []\n",
    "current_regime = \"Bull\"\n",
    "for i in range(n_days):\n",
    "    market_regime.append(current_regime)\n",
    "    # once a month, we consider a possible regime switch\n",
    "    if i > 0 and trading_days[i].day == 1:\n",
    "        current_regime = next_regime(current_regime)\n",
    "market_regime = np.array(market_regime)\n",
    "\n",
    "def regime_drift_offset(regime):\n",
    "    # e.g. in a Bull regime, we add +0.05 to annual drift, Bear => -0.02\n",
    "    if regime == \"Bull\":\n",
    "        return 0.05\n",
    "    else:\n",
    "        return -0.02\n",
    "\n",
    "def sentiment_drift_offset(sent):\n",
    "    # e.g. scale sentiment by 0.1 => offset\n",
    "    return 0.1 * sent\n",
    "\n",
    "# We'll also define a simple sector rotation effect: each year we pick a \"favored\" sector\n",
    "# that gets an extra +0.03 drift, and a \"disfavored\" sector that gets -0.02\n",
    "year_to_favored = {}\n",
    "year_to_disfavored = {}\n",
    "for year in range(start_date.year, end_date.year + 1):\n",
    "    favored = np.random.choice(SECTORS)\n",
    "    disfavored = np.random.choice([s for s in SECTORS if s != favored])\n",
    "    year_to_favored[year] = favored\n",
    "    year_to_disfavored[year] = disfavored\n",
    "\n",
    "def sector_rotation_offset(sector, date):\n",
    "    y = date.year\n",
    "    if sector == year_to_favored[y]:\n",
    "        return 0.03\n",
    "    elif sector == year_to_disfavored[y]:\n",
    "        return -0.02\n",
    "    else:\n",
    "        return 0.0\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Company Data & Growth Profiles\n",
    "# -------------------------------\n",
    "LIFE_CYCLES = [\"Growth\", \"Mature\", \"Decline\"]\n",
    "def life_cycle_drift(lifecycle):\n",
    "    # Example: Growth => +0.05, Mature => +0.02, Decline => -0.01\n",
    "    if lifecycle == \"Growth\":\n",
    "        return 0.05\n",
    "    elif lifecycle == \"Mature\":\n",
    "        return 0.02\n",
    "    else:\n",
    "        return -0.01\n",
    "\n",
    "companies = [f\"Company{i+1}\" for i in range(NUM_COMPANIES)]\n",
    "company_profiles = {}\n",
    "\n",
    "for c in companies:\n",
    "    sector = np.random.choice(SECTORS)\n",
    "    mc = np.random.choice(MARKET_CAPS)\n",
    "    lc = np.random.choice(LIFE_CYCLES, p=[0.4, 0.4, 0.2])  # 40% growth, 40% mature, 20% decline\n",
    "    init_vals = {}\n",
    "    vol_vals = {}\n",
    "    for est in ESTIMATE_TYPES:\n",
    "        init_vals[est] = np.random.uniform(*ESTIMATE_PARAMS[est][\"init\"])\n",
    "        vol_vals[est] = np.random.uniform(*ESTIMATE_PARAMS[est][\"vol\"])\n",
    "    company_profiles[c] = {\n",
    "        \"Sector\": sector,\n",
    "        \"MarketCap\": mc,\n",
    "        \"LifeCycle\": lc,\n",
    "        \"Initial\": init_vals,\n",
    "        \"Volatility\": vol_vals\n",
    "    }\n",
    "\n",
    "# -------------------------------\n",
    "# 5. Macroeconomic & Sector Shocks\n",
    "# -------------------------------\n",
    "shock_factor_market = np.ones(n_days)  # factor that modifies drift for entire market\n",
    "shock_factor_sector = np.ones((n_days, len(SECTORS)))  # sector-specific factor\n",
    "\n",
    "def generate_shocks():\n",
    "    \"\"\"\n",
    "    Each month, small chance of a macro shock or sector shock that modifies\n",
    "    the daily drift for a short period (5-10 days).\n",
    "    \"\"\"\n",
    "    for i in range(1, n_days):\n",
    "        if trading_days[i].day == 1:\n",
    "            # macro shock\n",
    "            if np.random.rand() < 0.05:\n",
    "                shock_len = np.random.randint(5, 11)\n",
    "                shock_mag = np.random.uniform(-0.05, 0.05)  # can be up or down\n",
    "                for j in range(i, min(i + shock_len, n_days)):\n",
    "                    shock_factor_market[j] += shock_mag\n",
    "            # sector shock\n",
    "            if np.random.rand() < 0.1:\n",
    "                sector_hit = np.random.choice(SECTORS)\n",
    "                idx_sec = SECTORS.index(sector_hit)\n",
    "                shock_len = np.random.randint(5, 11)\n",
    "                shock_mag = np.random.uniform(-0.08, 0.08)\n",
    "                for j in range(i, min(i + shock_len, n_days)):\n",
    "                    shock_factor_sector[j, idx_sec] += shock_mag\n",
    "\n",
    "generate_shocks()\n",
    "\n",
    "# -------------------------------\n",
    "# 6. Company-Specific Events\n",
    "# -------------------------------\n",
    "events = {day: {} for day in trading_days}\n",
    "\n",
    "def generate_company_events():\n",
    "    \"\"\"\n",
    "    Random events: earnings_surprise, M&A, product_launch.\n",
    "    Each quarter, there's a small chance for each event.\n",
    "    \"\"\"\n",
    "    for c in companies:\n",
    "        for q_day in quarter_ends:\n",
    "            if np.random.rand() < 0.05:\n",
    "                events[q_day].setdefault(c, []).append(\"earnings_surprise\")\n",
    "            if np.random.rand() < 0.01:\n",
    "                events[q_day].setdefault(c, []).append(\"M&A\")\n",
    "            if np.random.rand() < 0.02:\n",
    "                if company_profiles[c][\"Sector\"] in [\"Healthcare\", \"Consumer Goods\"]:\n",
    "                    events[q_day].setdefault(c, []).append(\"product_launch\")\n",
    "\n",
    "generate_company_events()\n",
    "\n",
    "def apply_company_event(c, day_idx, metric_values, metric, S):\n",
    "    \"\"\"\n",
    "    Applies any event that occurs on this day for this company, possibly adjusting S.\n",
    "    \"\"\"\n",
    "    d = trading_days[day_idx]\n",
    "    if d in events and c in events[d]:\n",
    "        for ev in events[d][c]:\n",
    "            if ev == \"earnings_surprise\":\n",
    "                jump_scale = 0.15 if metric == \"Stock Price\" else 0.10\n",
    "                jump = np.random.uniform(-jump_scale, jump_scale)\n",
    "                S *= (1 + jump)\n",
    "            elif ev == \"M&A\":\n",
    "                jump_scale = 0.2 if metric == \"Stock Price\" else 0.3\n",
    "                jump = np.random.uniform(-jump_scale, jump_scale)\n",
    "                S *= (1 + jump)\n",
    "            elif ev == \"product_launch\":\n",
    "                if metric in [\"Revenue\", \"EBITDA\", \"EBIT\"]:\n",
    "                    jump = np.random.uniform(0.0, 0.1)\n",
    "                    S *= (1 + jump)\n",
    "                elif metric == \"Stock Price\":\n",
    "                    jump = np.random.uniform(0.0, 0.05)\n",
    "                    S *= (1 + jump)\n",
    "                elif metric == \"EPS\":\n",
    "                    jump = np.random.uniform(0.0, 0.08)\n",
    "                    S *= (1 + jump)\n",
    "    return S\n",
    "\n",
    "# -------------------------------\n",
    "# 7. Cross-Metric Correlation & Idiosyncratic Jumps\n",
    "# -------------------------------\n",
    "def generate_correlation_matrix(dim):\n",
    "    A = np.random.normal(size=(dim, dim))\n",
    "    cov = np.dot(A, A.T)  # random SPD matrix\n",
    "    d = np.sqrt(np.diag(cov))\n",
    "    corr = cov / np.outer(d, d)\n",
    "    return corr\n",
    "\n",
    "def jump_diffusion_poisson(lam=0.0002):\n",
    "    \"\"\"\n",
    "    Very rare jump. If triggered, random magnitude in [-10%, +10%].\n",
    "    \"\"\"\n",
    "    if np.random.rand() < lam:\n",
    "        jump = np.random.uniform(-0.1, 0.1)\n",
    "        return (1 + jump)\n",
    "    return 1.0\n",
    "\n",
    "company_metric_corr = {}\n",
    "for c in companies:\n",
    "    dim = len(ESTIMATE_TYPES)\n",
    "    corr = generate_correlation_matrix(dim)\n",
    "    try:\n",
    "        L = cholesky(corr)\n",
    "    except np.linalg.LinAlgError:\n",
    "        L = np.eye(dim)\n",
    "    company_metric_corr[c] = L\n",
    "\n",
    "# -------------------------------\n",
    "# 8. Seasonal Patterns for Some Metrics\n",
    "# -------------------------------\n",
    "def seasonal_factor(metric, sector, day):\n",
    "    if metric == \"Revenue\" and sector == \"Consumer Goods\":\n",
    "        if day.quarter == 4:\n",
    "            return 1.05\n",
    "    return 1.0\n",
    "\n",
    "# -------------------------------\n",
    "# 9. Analyst Coverage & Behavior\n",
    "# -------------------------------\n",
    "analysts = [f\"Analyst{i+1}\" for i in range(NUM_ANALYSTS)]\n",
    "\n",
    "# Assign each analyst a random start date within the simulation period\n",
    "analyst_start_date = {\n",
    "    a: np.random.choice(trading_days[:int(n_days * 0.8)])  # 80% of range to ensure enough data\n",
    "    for a in analysts\n",
    "}\n",
    "\n",
    "# We now define coverage so that Large Caps have more coverage, Small Caps fewer\n",
    "coverage = {}\n",
    "for c in companies:\n",
    "    coverage[c] = []\n",
    "    mc = company_profiles[c][\"MarketCap\"]\n",
    "    if mc == \"Large Cap\":\n",
    "        min_cov, max_cov = 15, 25\n",
    "    elif mc == \"Mid Cap\":\n",
    "        min_cov, max_cov = 8, 15\n",
    "    else:  # Small Cap\n",
    "        min_cov, max_cov = 3, 8\n",
    "    possible_analysts = analysts\n",
    "    num_cov = np.random.randint(min_cov, max_cov + 1)\n",
    "\n",
    "    if len(possible_analysts) >= num_cov:\n",
    "        covered_analysts = np.random.choice(possible_analysts, size=num_cov, replace=False)\n",
    "    elif len(possible_analysts) > 0:\n",
    "        # fallback: sample with replacement or just use all available analysts\n",
    "        covered_analysts = np.random.choice(possible_analysts, size=min(len(possible_analysts), num_cov), replace=True)\n",
    "    else:\n",
    "        # if literally no analysts are available, skip coverage for this company\n",
    "        continue\n",
    "\n",
    "    coverage[c].extend(covered_analysts)\n",
    "\n",
    "\n",
    "def update_coverage_each_year():\n",
    "    \"\"\"\n",
    "    Simulates analysts dropping and picking up coverage over time.\n",
    "    \"\"\"\n",
    "    for c in companies:\n",
    "        current_analysts = coverage[c]\n",
    "        new_analysts = []\n",
    "\n",
    "        # Drop some analysts randomly (15% churn)\n",
    "        for a in current_analysts:\n",
    "            if np.random.rand() > 0.85:  # 15% chance to drop coverage\n",
    "                continue\n",
    "            new_analysts.append(a)\n",
    "\n",
    "        # Possibly add new analysts (1-3 per company)\n",
    "        needed = np.random.randint(1, 4)\n",
    "        while len(new_analysts) < len(current_analysts):\n",
    "            # Select analysts not already covering this company\n",
    "            candidates = [a for a in analysts if a not in new_analysts]\n",
    "            if len(candidates) == 0:\n",
    "                break  # no available new analysts left\n",
    "            a_new = np.random.choice(candidates)\n",
    "            new_analysts.append(a_new)\n",
    "            if len(new_analysts) >= len(current_analysts) + needed:\n",
    "                break\n",
    "\n",
    "        coverage[c] = new_analysts\n",
    "\n",
    "# ——————————————\n",
    "# 9.a. Cohort-based Analyst Reliability\n",
    "# ——————————————\n",
    "# (remove any previous `stars = …` or Beta-draw loops)\n",
    "\n",
    "# 1) define cohort sizes\n",
    "num = len(analysts)\n",
    "n_stars = int(0.30 * num)   # top 30%\n",
    "n_duds  = int(0.15 * num)   # bottom 15%\n",
    "\n",
    "# 2) randomly assign analysts into 3 cohorts\n",
    "pool       = analysts.copy()\n",
    "top_cohort = random.sample(pool, n_stars)\n",
    "for a in top_cohort: pool.remove(a)\n",
    "bot_cohort = random.sample(pool, n_duds)\n",
    "for a in bot_cohort: pool.remove(a)\n",
    "avg_cohort = pool  # the remaining 55%\n",
    "\n",
    "# 3) set Beta parameters per cohort\n",
    "cohort_params = {\n",
    "    \"top\": (5, 1),   # clustered near 1.0\n",
    "    \"avg\": (2, 2),   # around 0.5\n",
    "    \"bot\": (1, 5),   # clustered near 0.0\n",
    "}\n",
    "\n",
    "analyst_reliability = {}\n",
    "for a in analysts:\n",
    "    if   a in top_cohort:  α, β = cohort_params[\"top\"]\n",
    "    elif a in bot_cohort:  α, β = cohort_params[\"bot\"]\n",
    "    else:                   α, β = cohort_params[\"avg\"]\n",
    "\n",
    "    draw = np.random.beta(α, β)\n",
    "    # scale into [0.3, 0.95] so even duds aren’t always zero\n",
    "    base_rel = 0.3 + 0.65 * draw\n",
    "\n",
    "    # assign the same base_rel for every (sector, market-cap, metric)\n",
    "    analyst_reliability[a] = {\n",
    "        (s, mc, est): base_rel\n",
    "        for s  in SECTORS\n",
    "        for mc in MARKET_CAPS\n",
    "        for est in ESTIMATE_TYPES\n",
    "    }\n",
    "\n",
    "analyst_learning_rate = {a: np.random.uniform(-0.01, 0.02) for a in analysts}\n",
    "# Initial experience level (0 to 1), starts low\n",
    "analyst_experience = {a: np.random.uniform(0.1, 0.4) for a in analysts}\n",
    "\n",
    "# Analyst forecast bias: some are consistently optimistic (overestimate), some pessimistic\n",
    "# Analyst forecast bias: wider spread of optimism/pessimism (±5% σ)\n",
    "analyst_bias = {}\n",
    "for a in analysts:\n",
    "    analyst_bias[a] = np.random.normal(loc=0.0, scale=0.05)\n",
    "\n",
    "# Some analysts are stubborn and won't update their bias\n",
    "stubborn_analysts = set(np.random.choice(analysts, size=int(0.1 * NUM_ANALYSTS), replace=False))\n",
    "\n",
    "def herding_adjustment(predictions, weight=0.05):\n",
    "    \"\"\"Pull each forecast only 5% toward the group mean, preserving dispersion.\"\"\"\n",
    "    if not predictions:\n",
    "        return []\n",
    "    mean_pred = np.mean(predictions)\n",
    "    return [p + weight * (mean_pred - p) for p in predictions]\n",
    "\n",
    "def update_reliability_on_surprise(analyst, sector, mc, est, error):\n",
    "    base_rel = analyst_reliability[analyst][(sector, mc, est)]\n",
    "    if abs(error) > 0.3:\n",
    "        base_rel -= 0.02\n",
    "    base_rel = max(0.3, min(0.99, base_rel))\n",
    "    analyst_reliability[analyst][(sector, mc, est)] = base_rel\n",
    "\n",
    "# -------------------------------\n",
    "# 10. Putting it All Together (Daily Simulation + Quarterly Predictions)\n",
    "# -------------------------------\n",
    "real_paths = {c: {} for c in companies}\n",
    "for c in companies:\n",
    "    for est in ESTIMATE_TYPES:\n",
    "        real_paths[c][est] = np.zeros(n_days)\n",
    "\n",
    "# Initialize from \"Initial\"\n",
    "for c in companies:\n",
    "    for est in ESTIMATE_TYPES:\n",
    "        real_paths[c][est][0] = company_profiles[c][\"Initial\"][est]\n",
    "\n",
    "# Daily simulation\n",
    "for i in range(1, n_days):\n",
    "    date = trading_days[i]\n",
    "    dt = 1/252.0\n",
    "    reg = market_regime[i]\n",
    "    sentiment_val = market_sentiment[i]\n",
    "\n",
    "    # We'll apply macro/sector shocks too\n",
    "    macro_factor = shock_factor_market[i]\n",
    "\n",
    "    for c in companies:\n",
    "        sector = company_profiles[c][\"Sector\"]\n",
    "        mc = company_profiles[c][\"MarketCap\"]\n",
    "        lc = company_profiles[c][\"LifeCycle\"]\n",
    "\n",
    "        L = company_metric_corr[c]\n",
    "        dim = len(ESTIMATE_TYPES)\n",
    "\n",
    "        z = np.random.normal(0, 1, dim)\n",
    "        corr_z = L.dot(z)\n",
    "\n",
    "        lc_drift = life_cycle_drift(lc)\n",
    "        regime_offset = regime_drift_offset(reg)\n",
    "        sent_offset = sentiment_drift_offset(sentiment_val)\n",
    "        sector_rot = sector_rotation_offset(sector, date)\n",
    "\n",
    "        # Combine into an annual drift, then scale by shock_factor\n",
    "        annual_drift = (lc_drift + regime_offset + sent_offset + sector_rot)\n",
    "        # Apply macro factor and sector factor\n",
    "        idx_sec = SECTORS.index(sector)\n",
    "        # e.g. multiply drift by shock factors\n",
    "        annual_drift *= macro_factor\n",
    "        annual_drift *= shock_factor_sector[i, idx_sec]\n",
    "\n",
    "        for idx_est, est in enumerate(ESTIMATE_TYPES):\n",
    "            S_prev = real_paths[c][est][i-1]\n",
    "            vol = company_profiles[c][\"Volatility\"][est]\n",
    "\n",
    "            daily_drift = annual_drift / 252.0\n",
    "            dW = corr_z[idx_est] * np.sqrt(dt)\n",
    "\n",
    "            # Jump diffusion\n",
    "            jump_factor = jump_diffusion_poisson(lam=0.0002)\n",
    "\n",
    "            daily_ret = daily_drift - 0.5*(vol**2)*dt + vol*dW\n",
    "            daily_ret = np.clip(daily_ret, -0.03, 0.03)\n",
    "\n",
    "            S_new = S_prev * np.exp(daily_ret) * jump_factor\n",
    "            S_new *= seasonal_factor(est, sector, date)\n",
    "            S_new = apply_company_event(c, i, company_profiles[c], est, S_new)\n",
    "\n",
    "            real_paths[c][est][i] = S_new\n",
    "\n",
    "# Build final DataFrame of predictions with a \"reporting lag\"\n",
    "records = []\n",
    "revealed_values = {c: {est: {} for est in ESTIMATE_TYPES} for c in companies}\n",
    "\n",
    "for q_idx, q_day in enumerate(quarter_ends):\n",
    "    q_label = f\"Q{q_day.quarter} {q_day.year}\"\n",
    "\n",
    "    if q_idx < len(quarter_ends) - 1:\n",
    "        reveal_day = quarter_ends[q_idx+1]\n",
    "    else:\n",
    "        reveal_day = None\n",
    "\n",
    "    if q_day not in day_to_idx:\n",
    "        continue\n",
    "    q_idx_day = day_to_idx[q_day]\n",
    "\n",
    "    # Real values at quarter-end\n",
    "    for c in companies:\n",
    "      for est in ESTIMATE_TYPES:\n",
    "        for horizon in HORIZONS:\n",
    "            horizon_offset = {\n",
    "                \"Q0\": 0,\n",
    "                \"Q1\": 1,\n",
    "                \"Q2\": 2,\n",
    "            }.get(horizon, 0)\n",
    "\n",
    "            if q_idx + horizon_offset >= len(quarter_ends):\n",
    "                continue  # skip if horizon goes past simulation range\n",
    "\n",
    "            target_day = quarter_ends[q_idx + horizon_offset]\n",
    "            target_idx = day_to_idx.get(target_day, None)\n",
    "            if target_idx is None:\n",
    "                continue\n",
    "\n",
    "            real_val = real_paths[c][est][target_idx]\n",
    "            revealed_values[c][est][horizon] = real_val\n",
    "\n",
    "    from pandas.tseries.offsets import BMonthEnd\n",
    "    revision_days = [\n",
    "      q_day - BMonthEnd(3),\n",
    "      q_day - BMonthEnd(2),\n",
    "      q_day - BMonthEnd(1)\n",
    "    ]\n",
    "\n",
    "    # Add initial forecasts BEFORE any revision\n",
    "    rev_label = \"Initial\"\n",
    "\n",
    "    for c in companies:\n",
    "        sector = company_profiles[c][\"Sector\"]\n",
    "        mc = company_profiles[c][\"MarketCap\"]\n",
    "        coverage_list = coverage[c]\n",
    "\n",
    "        for est in ESTIMATE_TYPES:\n",
    "            for horizon in [\"Q0\", \"Q1\", \"Q2\"]:\n",
    "                horizon_offset = {\n",
    "                    \"Q0\": 0,\n",
    "                    \"Q1\": 1,\n",
    "                    \"Q2\": 2\n",
    "                }[horizon]\n",
    "\n",
    "                if q_idx + horizon_offset >= len(quarter_ends):\n",
    "                    continue\n",
    "                target_day = quarter_ends[q_idx + horizon_offset]\n",
    "                target_idx = day_to_idx.get(target_day, None)\n",
    "                if target_idx is None:\n",
    "                    continue\n",
    "                real_val = real_paths[c][est][target_idx]\n",
    "\n",
    "                init_preds = []\n",
    "                active_analysts = []\n",
    "                for a in coverage_list:\n",
    "                    if q_day >= analyst_start_date[a] and np.random.rand() < 0.8:\n",
    "                        active_analysts.append(a)\n",
    "\n",
    "                for a in active_analysts:\n",
    "                    base_rel = analyst_reliability[a][(sector, mc, est)]\n",
    "                    # wider base noise plus per-analyst rookies boost\n",
    "                    noise_vol = np.random.uniform(0.1, 0.4)\n",
    "                    error_std = (1 - base_rel) * noise_vol\n",
    "                    error_factor = np.random.normal(1 + analyst_bias[a], error_std)\n",
    "                    init_pred = real_val * error_factor\n",
    "                    init_preds.append(init_pred)\n",
    "\n",
    "                final_preds = herding_adjustment(init_preds)\n",
    "\n",
    "                for idx_a, a in enumerate(active_analysts):\n",
    "                    pred_val = final_preds[idx_a]\n",
    "                    records.append([\n",
    "                        q_label, est, pred_val, None,\n",
    "                        c, a, np.random.choice(BANKS),\n",
    "                        company_profiles[c][\"MarketCap\"],\n",
    "                        sector,\n",
    "                        analyst_start_date[a],\n",
    "                        horizon,\n",
    "                        rev_label  # this will say \"Initial\"\n",
    "                    ])\n",
    "\n",
    "    for rev_day in revision_days:\n",
    "        if rev_day not in day_to_idx:\n",
    "            continue\n",
    "        rev_label = f\"Rev {rev_day.strftime('%Y-%m-%d')}\"\n",
    "\n",
    "        for c in companies:\n",
    "            sector = company_profiles[c][\"Sector\"]\n",
    "            mc = company_profiles[c][\"MarketCap\"]\n",
    "            coverage_list = coverage[c]\n",
    "\n",
    "            for est in ESTIMATE_TYPES:\n",
    "                for horizon in [\"Q0\", \"Q1\", \"Q2\"]:  # only short-term forecasts\n",
    "\n",
    "                    horizon_offset = {\n",
    "                        \"Q0\": 0,\n",
    "                        \"Q1\": 1,\n",
    "                        \"Q2\": 2\n",
    "                    }[horizon]\n",
    "\n",
    "                    if q_idx + horizon_offset >= len(quarter_ends):\n",
    "                        continue\n",
    "                    target_day = quarter_ends[q_idx + horizon_offset]\n",
    "                    target_idx = day_to_idx.get(target_day, None)\n",
    "                    if target_idx is None:\n",
    "                        continue\n",
    "                    real_val = real_paths[c][est][target_idx]\n",
    "\n",
    "                    init_preds = []\n",
    "                    active_analysts = []\n",
    "                    for a in coverage_list:\n",
    "                        if rev_day >= analyst_start_date[a] and np.random.rand() < 0.8:\n",
    "                            active_analysts.append(a)\n",
    "\n",
    "                    for a in active_analysts:\n",
    "                        base_rel = analyst_reliability[a][(sector, mc, est)]\n",
    "                        noise_vol = np.random.uniform(0.1, 0.4)\n",
    "                        error_std = (1 - base_rel) * noise_vol\n",
    "                        error_factor = np.random.normal(1 + analyst_bias[a], error_std)\n",
    "                        init_pred = real_val * error_factor\n",
    "                        init_preds.append(init_pred)\n",
    "\n",
    "                    final_preds = herding_adjustment(init_preds)\n",
    "\n",
    "                    for idx_a, a in enumerate(active_analysts):\n",
    "                        pred_val = final_preds[idx_a]\n",
    "                        records.append([\n",
    "                            q_label, est, pred_val, None,\n",
    "                            c, a, np.random.choice(BANKS),\n",
    "                            company_profiles[c][\"MarketCap\"],\n",
    "                            sector,\n",
    "                            analyst_start_date[a],\n",
    "                            horizon,\n",
    "                            rev_label,\n",
    "                        ])\n",
    "\n",
    "    # Possibly update coverage each year\n",
    "    if q_day.quarter == 1:\n",
    "        update_coverage_each_year()\n",
    "\n",
    "df = pd.DataFrame(records, columns=[\n",
    "    \"Quarter\", \"Estimate Type\", \"Predicted Value\", \"Real Value\",\n",
    "    \"Company\", \"Analyst\", \"Bank\", \"Market Cap\", \"Sector\", \"Start Date\", \"Horizon\", \"Revision Time\"\n",
    "])\n",
    "\n",
    "# Fill in Real Value for each quarter\n",
    "real_value_by_quarter = {}\n",
    "for q_day in quarter_ends:\n",
    "    q_label = f\"Q{q_day.quarter} {q_day.year}\"\n",
    "    if q_day in day_to_idx:\n",
    "        idx_day = day_to_idx[q_day]\n",
    "        for c in companies:\n",
    "            for est in ESTIMATE_TYPES:\n",
    "                real_value_by_quarter[(q_label, c, est)] = real_paths[c][est][idx_day]\n",
    "\n",
    "for i in range(len(df)):\n",
    "    row = df.iloc[i]\n",
    "    q_label = row[\"Quarter\"]\n",
    "    c = row[\"Company\"]\n",
    "    est = row[\"Estimate Type\"]\n",
    "    horizon = row[\"Horizon\"]\n",
    "\n",
    "    if c in revealed_values and est in revealed_values[c] and horizon in revealed_values[c][est]:\n",
    "        df.at[i, \"Real Value\"] = revealed_values[c][est][horizon]\n",
    "\n",
    "# Final pass: update reliability based on errors\n",
    "for i in range(len(df)):\n",
    "    row = df.iloc[i]\n",
    "    c = row[\"Company\"]\n",
    "    est = row[\"Estimate Type\"]\n",
    "    sector = company_profiles[c][\"Sector\"]\n",
    "    mc = company_profiles[c][\"MarketCap\"]\n",
    "    a = row[\"Analyst\"]\n",
    "    pred = row[\"Predicted Value\"]\n",
    "    rv = row[\"Real Value\"]\n",
    "    if rv is not None and rv != 0:\n",
    "        error_ratio = (pred - rv) / rv\n",
    "        update_reliability_on_surprise(a, sector, mc, est, error_ratio)\n",
    "\n",
    "        # also apply learning based on experience\n",
    "        base_rel = analyst_reliability[a][(sector, mc, est)]\n",
    "        experience = analyst_experience[a]\n",
    "        learning_rate = analyst_learning_rate[a]\n",
    "\n",
    "        # Experience modulates the effect of learning\n",
    "        delta = learning_rate * experience\n",
    "        new_rel = base_rel + delta\n",
    "        new_rel = max(0.3, min(0.99, new_rel))\n",
    "        analyst_reliability[a][(sector, mc, est)] = new_rel\n",
    "\n",
    "        # Analyst gains experience gradually\n",
    "        analyst_experience[a] = min(1.0, experience + 0.002)\n",
    "\n",
    "        if a not in stubborn_analysts:\n",
    "          # Adjust bias based on error direction (analysts learn over time)\n",
    "          bias_adj = -0.1 * error_ratio  # e.g., if error_ratio > 0, reduce positive bias\n",
    "          analyst_bias[a] += bias_adj\n",
    "          analyst_bias[a] = max(-0.1, min(0.1, analyst_bias[a]))  # clamp between [-10%, +10%]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overwrite the Real Value column using the correct mapping\n",
    "df[\"Real Value\"] = df.apply(\n",
    "    lambda row: real_value_by_quarter[\n",
    "        (row[\"Quarter\"], row[\"Company\"], row[\"Estimate Type\"])\n",
    "    ],\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Estimate Type</th>\n",
       "      <th>Predicted Value</th>\n",
       "      <th>Real Value</th>\n",
       "      <th>Company</th>\n",
       "      <th>Analyst</th>\n",
       "      <th>Bank</th>\n",
       "      <th>Market Cap</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Start Date</th>\n",
       "      <th>Horizon</th>\n",
       "      <th>Revision Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q1 2013</td>\n",
       "      <td>Stock Price</td>\n",
       "      <td>3.083182e+01</td>\n",
       "      <td>2.906252e+01</td>\n",
       "      <td>Company5</td>\n",
       "      <td>Analyst513</td>\n",
       "      <td>Credit Suisse</td>\n",
       "      <td>Mid Cap</td>\n",
       "      <td>Technology</td>\n",
       "      <td>2013-02-19</td>\n",
       "      <td>Q0</td>\n",
       "      <td>Initial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q1 2013</td>\n",
       "      <td>Stock Price</td>\n",
       "      <td>3.657365e+01</td>\n",
       "      <td>2.906252e+01</td>\n",
       "      <td>Company5</td>\n",
       "      <td>Analyst513</td>\n",
       "      <td>Morgan Stanley</td>\n",
       "      <td>Mid Cap</td>\n",
       "      <td>Technology</td>\n",
       "      <td>2013-02-19</td>\n",
       "      <td>Q1</td>\n",
       "      <td>Initial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q1 2013</td>\n",
       "      <td>Stock Price</td>\n",
       "      <td>4.628826e+01</td>\n",
       "      <td>2.906252e+01</td>\n",
       "      <td>Company5</td>\n",
       "      <td>Analyst513</td>\n",
       "      <td>Barclays</td>\n",
       "      <td>Mid Cap</td>\n",
       "      <td>Technology</td>\n",
       "      <td>2013-02-19</td>\n",
       "      <td>Q2</td>\n",
       "      <td>Initial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q1 2013</td>\n",
       "      <td>EBITDA</td>\n",
       "      <td>1.291998e+09</td>\n",
       "      <td>1.264608e+09</td>\n",
       "      <td>Company5</td>\n",
       "      <td>Analyst513</td>\n",
       "      <td>Barclays</td>\n",
       "      <td>Mid Cap</td>\n",
       "      <td>Technology</td>\n",
       "      <td>2013-02-19</td>\n",
       "      <td>Q0</td>\n",
       "      <td>Initial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q1 2013</td>\n",
       "      <td>EBITDA</td>\n",
       "      <td>1.221465e+09</td>\n",
       "      <td>1.264608e+09</td>\n",
       "      <td>Company5</td>\n",
       "      <td>Analyst513</td>\n",
       "      <td>JP Morgan</td>\n",
       "      <td>Mid Cap</td>\n",
       "      <td>Technology</td>\n",
       "      <td>2013-02-19</td>\n",
       "      <td>Q1</td>\n",
       "      <td>Initial</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Quarter Estimate Type  Predicted Value    Real Value   Company     Analyst  \\\n",
       "0  Q1 2013   Stock Price     3.083182e+01  2.906252e+01  Company5  Analyst513   \n",
       "1  Q1 2013   Stock Price     3.657365e+01  2.906252e+01  Company5  Analyst513   \n",
       "2  Q1 2013   Stock Price     4.628826e+01  2.906252e+01  Company5  Analyst513   \n",
       "3  Q1 2013        EBITDA     1.291998e+09  1.264608e+09  Company5  Analyst513   \n",
       "4  Q1 2013        EBITDA     1.221465e+09  1.264608e+09  Company5  Analyst513   \n",
       "\n",
       "             Bank Market Cap      Sector Start Date Horizon Revision Time  \n",
       "0   Credit Suisse    Mid Cap  Technology 2013-02-19      Q0       Initial  \n",
       "1  Morgan Stanley    Mid Cap  Technology 2013-02-19      Q1       Initial  \n",
       "2        Barclays    Mid Cap  Technology 2013-02-19      Q2       Initial  \n",
       "3        Barclays    Mid Cap  Technology 2013-02-19      Q0       Initial  \n",
       "4       JP Morgan    Mid Cap  Technology 2013-02-19      Q1       Initial  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Initial', 'Rev 2013-01-31', 'Rev 2013-02-28', 'Rev 2013-03-29',\n",
       "       'Rev 2013-04-30', 'Rev 2013-05-31', 'Rev 2013-06-28',\n",
       "       'Rev 2013-07-31', 'Rev 2013-08-30', 'Rev 2013-09-30',\n",
       "       'Rev 2013-10-31', 'Rev 2013-11-29', 'Rev 2013-12-31',\n",
       "       'Rev 2014-01-31', 'Rev 2014-02-28', 'Rev 2014-03-31',\n",
       "       'Rev 2014-04-30', 'Rev 2014-05-30', 'Rev 2014-06-30',\n",
       "       'Rev 2014-07-31', 'Rev 2014-08-29', 'Rev 2014-09-30',\n",
       "       'Rev 2014-10-31', 'Rev 2014-11-28', 'Rev 2014-12-31',\n",
       "       'Rev 2015-01-30', 'Rev 2015-02-27', 'Rev 2015-03-31',\n",
       "       'Rev 2015-04-30', 'Rev 2015-05-29', 'Rev 2015-06-30',\n",
       "       'Rev 2015-07-31', 'Rev 2015-08-31', 'Rev 2015-09-30',\n",
       "       'Rev 2015-10-30', 'Rev 2015-11-30', 'Rev 2015-12-31',\n",
       "       'Rev 2016-01-29', 'Rev 2016-02-29', 'Rev 2016-03-31',\n",
       "       'Rev 2016-04-29', 'Rev 2016-05-31', 'Rev 2016-06-30',\n",
       "       'Rev 2016-07-29', 'Rev 2016-08-31', 'Rev 2016-09-30',\n",
       "       'Rev 2016-10-31', 'Rev 2016-11-30', 'Rev 2016-12-30',\n",
       "       'Rev 2017-01-31', 'Rev 2017-02-28', 'Rev 2017-03-31',\n",
       "       'Rev 2017-04-28', 'Rev 2017-05-31', 'Rev 2017-06-30',\n",
       "       'Rev 2017-07-31', 'Rev 2017-08-31', 'Rev 2017-09-29',\n",
       "       'Rev 2017-10-31', 'Rev 2017-11-30', 'Rev 2017-12-29',\n",
       "       'Rev 2018-01-31', 'Rev 2018-02-28', 'Rev 2018-03-30',\n",
       "       'Rev 2018-04-30', 'Rev 2018-05-31', 'Rev 2018-06-29',\n",
       "       'Rev 2018-07-31', 'Rev 2018-08-31', 'Rev 2018-09-28',\n",
       "       'Rev 2018-10-31', 'Rev 2018-11-30', 'Rev 2018-12-31',\n",
       "       'Rev 2019-01-31', 'Rev 2019-02-28', 'Rev 2019-03-29',\n",
       "       'Rev 2019-04-30', 'Rev 2019-05-31', 'Rev 2019-06-28',\n",
       "       'Rev 2019-07-31', 'Rev 2019-08-30', 'Rev 2019-09-30',\n",
       "       'Rev 2019-10-31', 'Rev 2019-11-29', 'Rev 2019-12-31',\n",
       "       'Rev 2020-01-31', 'Rev 2020-02-28', 'Rev 2020-03-31',\n",
       "       'Rev 2020-04-30', 'Rev 2020-05-29', 'Rev 2020-06-30',\n",
       "       'Rev 2020-07-31', 'Rev 2020-08-31', 'Rev 2020-09-30',\n",
       "       'Rev 2020-10-30', 'Rev 2020-11-30', 'Rev 2020-12-31',\n",
       "       'Rev 2021-01-29', 'Rev 2021-02-26', 'Rev 2021-03-31',\n",
       "       'Rev 2021-04-30', 'Rev 2021-05-31', 'Rev 2021-06-30',\n",
       "       'Rev 2021-07-30', 'Rev 2021-08-31', 'Rev 2021-09-30',\n",
       "       'Rev 2021-10-29', 'Rev 2021-11-30', 'Rev 2021-12-31',\n",
       "       'Rev 2022-01-31', 'Rev 2022-02-28', 'Rev 2022-03-31',\n",
       "       'Rev 2022-04-29', 'Rev 2022-05-31', 'Rev 2022-06-30',\n",
       "       'Rev 2022-07-29', 'Rev 2022-08-31', 'Rev 2022-09-30',\n",
       "       'Rev 2022-10-31', 'Rev 2022-11-30'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Revision Time\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13744263, 12)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (aws_test)",
   "language": "python",
   "name": "aws_test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
